{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crawler Description\n",
    "\n",
    "This crawler downloads DEXs swap data from Flipside Crypto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_path = \"/Users/zhicong/Desktop/KCL/Ethereum_DEX_Data/dex_swaps\"  # path to store PDFs\n",
    "\n",
    "os.chdir(download_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiate Selenium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromeOptions = webdriver.ChromeOptions()\n",
    "# Get through DDos Protection by Cloudflare\n",
    "chromeOptions.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "# Set download paths\n",
    "prefs = {\"download.default_directory\": download_path}\n",
    "chromeOptions.add_experimental_option(\"prefs\", prefs)\n",
    "driver = webdriver.Chrome(service = ChromeService(ChromeDriverManager().install()), options = chromeOptions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open Flipside Crypto and login."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://flipsidecrypto.xyz/\")\n",
    "WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, \"/html/body/div[1]/div[3]/div[1]/div[1]/div/nav/div[9]/div/button[2]\"))).click()\n",
    "time.sleep(np.random.randint(5, 10))\n",
    "\n",
    "# Enter username and password\n",
    "driver.find_element(By.XPATH, \"//*[@id='username']\").send_keys(\"zhiconghu@gmail.com\")\n",
    "driver.find_element(By.XPATH, \"//*[@id='password']\").send_keys(\"Zhicong12345\")\n",
    "driver.find_element(By.XPATH, \"/html/body/div/main/section/div/div/div/form/div[3]\").click()\n",
    "time.sleep(np.random.randint(10, 15))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the query named \"Temp\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the query with name \"Temp\"\n",
    "query_collections = driver.find_elements(By.XPATH, \"//a/div[@class='flex items-center justify-between w-full']\")\n",
    "for i in query_collections:\n",
    "    if i.get_attribute(\"innerText\") == \"Temp\":\n",
    "        i.find_element(By.XPATH, \"./p\").click()\n",
    "        break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the SQL code for query request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this part if starting from no data\n",
    "#i = 1\n",
    "#searched_rows = \"100000\"\n",
    "#block_range = \"\"\n",
    "# Run this part if starting with data, let i be the number of the latest data file\n",
    "i = 1478\n",
    "searched_rows = \"100000\"\n",
    "block_range = pd.read_csv(os.path.join(download_path, \"DEXs_swaps_\" + str(i) + \".csv\"), on_bad_lines = 'skip', low_memory = False).dropna()['BLOCK_NUMBER'].iloc[-1]\n",
    "block_range = str(block_range)\n",
    "i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "while searched_rows == \"100000\":\n",
    "\n",
    "    # Create SQL code for search\n",
    "    sql_code_select = \"SELECT block_number, block_timestamp, tx_hash, sender, tx_to, platform, pool_name, contract_address, event_name, amount_in, symbol_in, amount_out, symbol_out \"\n",
    "    sql_code_from = \"FROM ethereum.core.ez_dex_swaps \"\n",
    "    sql_code_where_platform = \"WHERE platform IN ('uniswap-v2','uniswap-v3','balancer','curve','sushiswap') \"\n",
    "    sql_code_where_block = \"AND block_number <= '\" + block_range + \"' \" \n",
    "    sql_code_order = \"ORDER BY block_number DESC\"\n",
    "\n",
    "    if block_range == \"\":\n",
    "        sql_code = sql_code_select + sql_code_from + sql_code_where_platform + sql_code_order\n",
    "    else:\n",
    "        sql_code = sql_code_select + sql_code_from + sql_code_where_platform + sql_code_where_block + sql_code_order\n",
    "\n",
    "    # Fill SQL code and run query\n",
    "    time.sleep(np.random.randint(2, 3))\n",
    "    driver.find_element(By.XPATH, \"//div[@class='cm-activeLine cm-line']\").clear()\n",
    "    driver.find_element(By.XPATH, \"//div[@class='cm-content']\").send_keys(sql_code)\n",
    "    time.sleep(np.random.randint(4, 5))\n",
    "    driver.find_element(By.XPATH, \"/html/body/div[1]/div[3]/div[2]/div[2]/div[1]/div[2]/div[1]\").click()\n",
    "    time.sleep(np.random.randint(2, 3))\n",
    "\n",
    "    # Wait for query to be executed then download data\n",
    "    WebDriverWait(driver, 600).until(EC.element_to_be_clickable((By.XPATH, \"/html/body/div[1]/div[3]/div[2]/div[2]/div[2]/div/div[1]/div[3]/div/div[2]/div/div/div/div[1]/div/div[2]/span[2]\"))).click()\n",
    "    \n",
    "    # Wait for the data to be downloaded then rename it\n",
    "    while not os.path.exists(\"download-query_run_results.csv\"):\n",
    "        time.sleep(1)\n",
    "    os.rename(\"download-query_run_results.csv\", \"DEXs_swaps_\" + str(i) + \".csv\")\n",
    "    time.sleep(np.random.randint(5, 10))\n",
    "\n",
    "    # See if all swap data have been download (i.e. searched rows = 100,000)\n",
    "    # This will break the loop when searched rows are no longer 100,000 meaning that all data have been downloaded\n",
    "    searched_rows = re.sub(\"[^0-9]\", \"\", driver.find_element(By.XPATH, \"//div[@class='flex mr-1']/div\").get_attribute(\"innerText\"))\n",
    "\n",
    "    # Read lastest block number in the previous download file\n",
    "    block_range = pd.read_csv(os.path.join(download_path, \"DEXs_swaps_\" + str(i) + \".csv\"), on_bad_lines = 'skip', low_memory = False).dropna()['BLOCK_NUMBER'].iloc[-1]\n",
    "    block_range = str(block_range)\n",
    "\n",
    "    # Add 1 to i\n",
    "    i = i + 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
