{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crawler Description\n",
    "\n",
    "This crawler downloads Uniswap v3 swap data from Flipside Crypto.\n",
    "\n",
    "Enter the pool address that you want to download for manually below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_path = \"/Users/zhicong/Desktop/KCL/Ethereum_DEX_Data/uniswapv3_swaps\"  # path to store PDFs\n",
    "pool_address = \"0x840deeef2f115cf50da625f7368c24af6fe74410\"\n",
    "pool_name = \"cbETH-WETH 500 10\"\n",
    "\n",
    "os.chdir(download_path)\n",
    "os.mkdir(pool_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiate Selenium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromeOptions = webdriver.ChromeOptions()\n",
    "#Get through DDos Protection by Cloudflare\n",
    "chromeOptions.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "#Set download paths\n",
    "prefs = {\"download.default_directory\": download_path}\n",
    "chromeOptions.add_experimental_option(\"prefs\", prefs)\n",
    "driver = webdriver.Chrome(service = ChromeService(ChromeDriverManager().install()), options = chromeOptions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open Flipside Crypto and login."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://flipsidecrypto.xyz/\")\n",
    "WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, \"/html/body/div[1]/div[3]/div[1]/div[1]/div/nav/div[9]/div/button[2]\"))).click()\n",
    "time.sleep(np.random.randint(5, 10))\n",
    "\n",
    "#Enter username and password\n",
    "driver.find_element(By.XPATH, \"//*[@id='username']\").send_keys(\"zhiconghu@gmail.com\")\n",
    "driver.find_element(By.XPATH, \"//*[@id='password']\").send_keys(\"Zhicong12345\")\n",
    "driver.find_element(By.XPATH, \"/html/body/div/main/section/div/div/div/form/div[3]\").click()\n",
    "time.sleep(np.random.randint(10, 15))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the query named \"Temp\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the query with name \"Temp\"\n",
    "query_collections = driver.find_elements(By.XPATH, \"//a/div[@class='flex items-center justify-between w-full']\")\n",
    "for i in query_collections:\n",
    "    if i.get_attribute(\"innerText\") == \"Temp\":\n",
    "        i.find_element(By.XPATH, \"./p\").click()\n",
    "        break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the SQL code for query request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "searched_rows = \"100000\"\n",
    "time_range = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "while searched_rows == \"100000\":\n",
    "\n",
    "    # Create SQL code for search\n",
    "    sql_code_select = \"SELECT pool_name, tx_hash, block_timestamp, sender, recipient, token0_symbol, amount0_adjusted, amount0_usd, token1_symbol, amount1_adjusted, amount1_usd, price_1_0 \"\n",
    "    sql_code_from = \"FROM ethereum.uniswapv3.ez_swaps \"\n",
    "    sql_code_where_pool = \"WHERE pool_address = '\" + pool_address + \"' \" \n",
    "    sql_code_where_time = \"AND block_timestamp <= '\" + time_range + \"' \" \n",
    "    sql_code_order = \"ORDER BY block_timestamp DESC\"\n",
    "\n",
    "    if time_range == \"\":\n",
    "        sql_code = sql_code_select + sql_code_from + sql_code_where_pool + sql_code_order\n",
    "    else:\n",
    "        sql_code = sql_code_select + sql_code_from + sql_code_where_pool + sql_code_where_time + sql_code_order\n",
    "\n",
    "    #Fill SQL code and run query\n",
    "    time.sleep(np.random.randint(2, 3))\n",
    "    driver.find_element(By.XPATH, \"//div[@class='cm-activeLine cm-line']\").clear()\n",
    "    driver.find_element(By.XPATH, \"//div[@class='cm-content']\").send_keys(sql_code)\n",
    "    time.sleep(np.random.randint(2, 3))\n",
    "    driver.find_element(By.XPATH, \"/html/body/div[1]/div[3]/div[2]/div[2]/div[1]/div[2]/div[1]\").click()\n",
    "    time.sleep(np.random.randint(2, 3))\n",
    "\n",
    "    #Wait for query to be executed then download data\n",
    "    WebDriverWait(driver, 600).until(EC.element_to_be_clickable((By.XPATH, \"/html/body/div[1]/div[3]/div[2]/div[2]/div[2]/div/div[1]/div[3]/div/div[2]/div/div/div/div[1]/div/div[2]/span[2]\"))).click()\n",
    "    \n",
    "    #Wait for the data to be downloaded then rename it and move to according folder\n",
    "    while not os.path.exists(\"download-query_run_results.csv\"):\n",
    "        time.sleep(1)\n",
    "    os.rename(\"download-query_run_results.csv\", pool_name + \"_\" + str(i) + \".csv\")\n",
    "    shutil.move(os.path.join(download_path, pool_name + \"_\" + str(i) + \".csv\"), \n",
    "                os.path.join(download_path, pool_name, pool_name + \"_\" + str(i) + \".csv\"))\n",
    "    time.sleep(np.random.randint(5, 10))\n",
    "\n",
    "    #See if all swap data have been download (i.e. searched rows = 100,000)\n",
    "    #This will break the loop when searched rows are no longer 100,000 meaning that all data have been downloaded\n",
    "    searched_rows = re.sub(\"[^0-9]\", \"\", driver.find_element(By.XPATH, \"//div[@class='flex mr-1']/div\").get_attribute(\"innerText\"))\n",
    "\n",
    "    #Read lastest date in the previous download file\n",
    "    time_range = pd.read_csv(os.path.join(download_path, pool_name, pool_name + \"_\" + str(i) + \".csv\"))[\"BLOCK_TIMESTAMP\"].dropna().iloc[-1][0:10]\n",
    "    time_range = time_range + \"T23:59:59Z\"\n",
    "\n",
    "    #Add 1 to i\n",
    "    i = i + 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
